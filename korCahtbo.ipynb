{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLQmadRqZNogw2BUqXJjhS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seobear95/AI-X-APP/blob/master/korCahtbo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6bgqBbytIQb",
        "outputId": "20a9b360-cc53-4634-fccd-8f4dc1fc457f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##<<읽어보기>>\n",
        "Hugging Face의 transformers 라이브러리는 공개적으로 사용 가능한 다양한 사전 학습된 모델을 제공하고 있습니다. 이 중에는 KoGPT-2라는 한국어 버전의 GPT-2 모델도 포함되어 있습니다. 이 모델은 한국어 자연어 처리 작업을 위해 특별히 학습되었습니다.\n",
        "\n",
        "PreTrainedTokenizerFast와 같은 클래스를 포함하는 transformers 라이브러리와 이 라이브러리가 의존하는 다른 라이브러리들이 설치됩니다. 이로써 transformers 라이브러리의 모든 기능을 사용할 수 있습니다.\n",
        "\n",
        "Hugging Face의 transformers 라이브러리는 많은 사전 학습된 자연어 처리 모델을 제공하며, 이를 사용해 쉽게 자연어 처리 작업을 수행할 수 있습니다."
      ],
      "metadata": {
        "id": "tDh5kILKtX0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n",
        "\n",
        "def chatbot_model():\n",
        "    # 모델과 토크나이저를 로드합니다.\n",
        "    tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\")\n",
        "    model = GPT2LMHeadModel.from_pretrained(\"skt/kogpt2-base-v2\")\n",
        "\n",
        "    # 무한 루프로 사용자의 입력을 받습니다.\n",
        "    try:\n",
        "        while True:\n",
        "            # 사용자로부터 입력을 받습니다.\n",
        "            input_text = input(\"You: \")\n",
        "\n",
        "            # 입력을 토크나이저로 인코딩하고 텐서로 변환합니다.\n",
        "            inputs = tokenizer.encode(input_text, return_tensors='pt')\n",
        "\n",
        "            # 모델을 이용해 응답을 생성합니다.\n",
        "            outputs = model.generate(inputs, max_length=150, num_return_sequences=1, no_repeat_ngram_size=2, temperature=0.7)\n",
        "\n",
        "            # 생성된 응답을 디코딩합니다.\n",
        "            response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "            print(f\"Chatbot: {response}\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nChatbot session ended.\")\n",
        "        return\n",
        "\n",
        "# 챗봇 모델을 실행합니다.\n",
        "chatbot_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaLvziZRtI1H",
        "outputId": "b94fddc5-0b79-45d9-e98c-745eb8f2c5b2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: America 에 대해 말해줘\n",
            "Chatbot: America 에 대해 말해줘야 할 것 같다.\n",
            "이런 식으로 해서 우리는 이 책을 읽어야 한다.\n",
            "이 책은 우리가 이 책에서 말하는 '진정한' '새로운' '이미지' 그리고 '창조적' 등을 모두 담고 있다.\n",
            "이 책의 가장 큰 특징은 이 책의 내용을 요약해 놓은 것이다.\n",
            "이 책을 읽는 사람들은 이 책이 '창조의 힘'을 보여주는 것이라고 생각한다.\n",
            "이 책이 창조적인 것의 중요성을 강조하는 것은 아니다.\n",
            "이 책에서 우리는 창조성을 어떻게 설명해야 하는지를 잘 알고 있다.\n",
            "창조적인 것은 '모든 것'이다.\n",
            "이것은 우리가 창조적으로 창조하는 것이 아니라 우리가 '다른 것'을 창조할 때 비로소 가능하다.\n",
            "이것이 창조성의 핵심이다.\n",
            "이러한 의미에서 이 책은 창조성이 무엇인지를 잘 설명하고 있다.\n",
            "그것은 창조성 안에 있는 '어떤 것'과 '\n",
            "\n",
            "Chatbot session ended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n",
        "\n",
        "def get_reply(user_input, chat_history):\n",
        "    # 토크나이저와 모델 초기화\n",
        "    tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\")\n",
        "    model = GPT2LMHeadModel.from_pretrained(\"skt/kogpt2-base-v2\")\n",
        "\n",
        "    # 사용자 입력과 채팅 기록을 결합\n",
        "    prompt = f\"{chat_history}\\nUser: {user_input}\\nBot:\"\n",
        "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    # 텍스트를 생성\n",
        "    outputs = model.generate(inputs, max_length=512, do_sample=True, temperature=0.8)\n",
        "    response = tokenizer.decode(outputs[:, inputs.shape[-1]:][0], skip_special_tokens=True)\n",
        "\n",
        "    # 채팅 기록 업데이트\n",
        "    chat_history = f\"{chat_history}\\nUser: {user_input}\\nBot: {response}\"\n",
        "\n",
        "    return response, chat_history\n",
        "\n",
        "chat_history = \"\"  # 채팅 기록을 초기화합니다.\n",
        "while True:\n",
        "    user_input = input(\"User: \")  # 사용자 입력을 받습니다.\n",
        "    bot_response, chat_history = get_reply(user_input, chat_history)\n",
        "    print(f\"Bot: {bot_response}\")  # 챗봇의 응답을 출력합니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QpnNt51qxQQw",
        "outputId": "f01d57bb-8b4c-4058-a1dd-6768f73cd83e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User: 너는 심리상담사야. 나는 오늘 기분이 슬프고 힘들어. 나에게 도움이 되는 상담글을 써줘\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bot: 너는 심리상담사야.\n",
            "Bot: 너는 심리상담사야.\n",
            "Bot: 너는 심리상담사야.\n",
            "Bot: 너는 심리상담사야.\n",
            "Bot: 너는 심리상담사야.\n",
            "Bot: 너는 심리상담사야.\n",
            "Bot: 너는 심리상담사야.\n",
            "Bot: 너는 심리상담사야.\n",
            "Bot: 너는 심리상담사야 마을과 마을 사람들 중에서\n",
            "Bot: 너는 심리상담사야의 사람이라고.\n",
            "Community: A Botman\n",
            "The University of Women - Tales\n",
            "Combat Message: Tales\n",
            "Community : The University of Women\n",
            "Community : The University of Women\n",
            "Community : The University of Women\n",
            "The University of Women\n",
            "Community : The University of Women\n",
            "Community : The University of Women\n",
            "Community : The University of Women\n",
            "Community : The University of Women\n",
            "Community : The University of Women\n",
            "Community : The University of Women\n",
            "Community : The University of Women\n",
            "Community : The University of Women\n",
            "Community : The University of Women\n",
            "Community : The University of Women\n",
            "Community : The University of Women\n",
            "Community : The University of Women\n",
            "Community : The University of Women\n",
            "Community : The University of Women\n",
            "Community : The University of Women\n",
            "Community : The University of Women\n",
            "Community : The Un 가끔씩 만나는\n",
            "Community : The University of Women\n",
            "Community : The University of Women\n",
            "Community : The University of Women\n",
            "Community : The University of Women\n",
            "Community : The University of Women\n",
            "Community : The University of Women\n",
            "Comm\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-4fcdf41cf917>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mchat_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m  \u001b[0;31m# 채팅 기록을 초기화합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"User: \"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 사용자 입력을 받습니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mbot_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchat_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_reply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchat_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Bot: {bot_response}\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 챗봇의 응답을 출력합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}