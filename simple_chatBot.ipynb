{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlhuwvZ51622+XWbTQw75f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seobear95/AI-X-APP/blob/master/simple_chatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOkF1Xw_kU41",
        "outputId": "4cfb52b6-7c76-4ab2-e333-07dbeffbf02e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "id": "NP-S0GWLkPrJ",
        "outputId": "666a2379-d676-452f-db32-0c767976373c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: Do you know about Seoul, Korea?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot: Do you know about Seoul, Korea? It's a city that's been around for a long time. It was founded by the Korean people in the late 19th century. The city is now a UNESCO World Heritage Site.\n",
            "\n",
            "So, what's the story behind the name?\n",
            "...\n",
            " (laughs)\n",
            ", and what do you think of the history of Seoul? I think it's very interesting. I don't know if it was a coincidence or not. But I do think that it is a very important place. And I'm sure that the people of Korea will be very proud of it. So, I hope that they will come to the city and see it as a place where they can live and work and enjoy their life.\n",
            "You: Tell me what you know about a city in Korea called Incheon\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot: Tell me what you know about a city in Korea called Incheon, and how it's different from other cities in the country.\n",
            "\n",
            "I think it is very different. I think the city is much more diverse. It's a very diverse city. There are a lot of different ethnicities. The people are very friendly. They are not afraid to talk to each other. And they are also very good at talking to their neighbors. So I don't think there is any problem with that. But I do think that there are some problems with the way the government is handling the situation. For example, the police are trying to get rid of the people who are involved in this. In the past, they have tried to take over the whole city, but they were unable to do that because of a lack of resources. Now, there's no problem. People are happy to go to the airport and go home. That's the only way to live. If you want to stay in a place like this, you have to pay taxes. You have a right to a home, a job, to have your own place. This is a country where you can live in your house. We have no problems. When you go out, it doesn't matter if you're a foreigner or a citizen. All you need is to be able to afford a house and a car. Even if it costs you a few hundred dollars, that's not a problem for you. A lot more people live here. Some of them are working. Others are just working and living. Most of these people have been here for a long time. Many of those people were here before the war. These people came here to work. Those people don' have any problems here, because they're not here because there was no war, so they don`t have problems there. However, I would say that the problem is that they didn`T have the money to buy a new house, or buy an apartment. Because of that, many of their people didn't have money. Therefore, when they came to Korea, their money was not there, which is why they had to leave. Then, after the Korean War, some of our people left. After the Korea War ended, we had a situation where we were able, in some cases, get a better house for them. Since then, our house has been renovated. Our people can now live with their parents. My wife and I have two children\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-2711c0d30eaa>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# 챗봇 모델을 실행합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mchatbot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-2711c0d30eaa>\u001b[0m in \u001b[0;36mchatbot_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# 사용자로부터 입력을 받습니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# 입력을 토크나이즈하고 텐서로 변환합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "# 필요한 라이브러리를 임포트합니다.\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "def chatbot_model():\n",
        "    # 모델과 토크나이저를 로드합니다.\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "    model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "    # 무한 루프로 사용자의 입력을 받습니다.\n",
        "    while True:\n",
        "        # 사용자로부터 입력을 받습니다.\n",
        "        input_text = input(\"You: \")\n",
        "\n",
        "        # 입력을 토크나이즈하고 텐서로 변환합니다.\n",
        "        inputs = tokenizer.encode(input_text, return_tensors='pt')\n",
        "\n",
        "        # 모델을 이용해 응답을 생성합니다.\n",
        "        outputs = model.generate(inputs, max_length=500, num_return_sequences=1, no_repeat_ngram_size=2, temperature=0.7)\n",
        "\n",
        "        # 생성된 응답을 디코딩합니다.\n",
        "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        print(f\"Chatbot: {response}\")\n",
        "\n",
        "# 챗봇 모델을 실행합니다.\n",
        "chatbot_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chatbot: Do you know about Seoul, Korea? It's a city that's been around for a long time. It was founded by the Korean people in the late 19th century. The city is now a UNESCO World Heritage Site.\n",
        "\n",
        "So, what's the story behind the name?\n",
        "...\n",
        " (laughs)\n",
        ", and what do you think of the history of Seoul? I think it's very interesting. I don't know if it was a coincidence or not. But I do think that it is a very important place. And I'm sure that the people of Korea will be very proud of it. So, I hope that they will come to the city and see it as a place where they can live and work and enjoy their life\n",
        "\n",
        "챗봇: 대한민국 서울을 아십니까? 오래전부터 존재해 온 도시입니다. 19세기 후반 한민족에 의해 세워졌다. 이 도시는 이제 유네스코 세계 문화 유산입니다.\n",
        "\n",
        "이름 뒤에 숨겨진 이야기는 무엇입니까? ... (웃음) 그리고 서울의 역사에 대해 어떻게 생각하세요? 매우 흥미롭다고 생각합니다. 우연의 일치인지 아닌지는 모르겠습니다. 하지만 매우 중요한 장소라고 생각합니다. 그리고 한국 국민들이 매우 자랑스러워할 것이라고 확신합니다. 그래서 그들이 도시로 와서 살고 일하고 삶을 즐길 수 있는 곳으로 보기를 바랍니다.\n"
      ],
      "metadata": {
        "id": "1B6p0H6PnEBN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chatbot: Tell me what you know about a city in Korea called Incheon, and how it's different from other cities in the country.\n",
        "\n",
        "I think it is very different. I think the city is much more diverse. It's a very diverse city. There are a lot of different ethnicities. The people are very friendly. They are not afraid to talk to each other. And they are also very good at talking to their neighbors. So I don't think there is any problem with that. But I do think that there are some problems with the way the government is handling the situation. For example, the police are trying to get rid of the people who are involved in this. In the past, they have tried to take over the whole city, but they were unable to do that because of a lack of resources. Now, there's no problem. People are happy to go to the airport and go home. That's the only way to live. If you want to stay in a place like this, you have to pay taxes. You have a right to a home, a job, to have your own place. This is a country where you can live in your house. We have no problems. When you go out, it doesn't matter if you're a foreigner or a citizen. All you need is to be able to afford a house and a car. Even if it costs you a few hundred dollars, that's not a problem for you. A lot more people live here. Some of them are working. Others are just working and living. Most of these people have been here for a long time. Many of those people were here before the war. These people came here to work. Those people don' have any problems here, because they're not here because there was no war, so they don`t have problems there. However, I would say that the problem is that they didn`T have the money to buy a new house, or buy an apartment. Because of that, many of their people didn't have money. Therefore, when they came to Korea, their money was not there, which is why they had to leave. Then, after the Korean War, some of our people left. After the Korea War ended, we had a situation where we were able, in some cases, get a better house for them. Since then, our house has been renovated. Our people can now live with their parents. My wife and I have two children\n",
        "\n",
        "\n",
        "챗봇: 한국의 인천이라는 도시에 대해 알고 있는 것과 인천이 다른 도시와 어떻게 다른지 알려주세요.\n",
        "\n",
        "나는 그것이 매우 다르다고 생각합니다. 나는 도시가 훨씬 더 다양하다고 생각한다. 매우 다양한 도시입니다. 다양한 인종이 많이 있습니다. 사람들은 매우 친절합니다. 그들은 서로 이야기하는 것을 두려워하지 않습니다. 그리고 그들은 또한 이웃과 이야기하는 데 매우 능숙합니다. 그래서 나는 그것에 아무런 문제가 없다고 생각합니다. 하지만 정부가 상황을 처리하는 방식에는 몇 가지 문제가 있다고 생각합니다. 예를 들어, 경찰은 이에 연루된 사람들을 제거하려고 합니다. 과거에 그들은 도시 전체를 점령하려고 시도했지만 자원이 부족하여 그렇게 할 수 없었습니다. 이제 아무 문제 없습니다. 사람들은 공항에 가고 집에 가는 것을 좋아합니다. 그것만이 살 길입니다. 이런 곳에 머물려면 세금을 내야 한다. 당신은 집, 직장, 자신만의 공간을 가질 권리가 있습니다. 집에서 살 수 있는 나라입니다. 문제가 없습니다. 외출할 때 외국인이건 내국인이건 상관없다. 필요한 것은 집과 자동차를 살 여유가 있는 것뿐입니다. 몇 백 달러의 비용이 들더라도 그것은 당신에게 문제가 되지 않습니다. 훨씬 더 많은 사람들이 이곳에 살고 있습니다. 그들 중 일부는 일하고 있습니다. 다른 사람들은 그냥 일하고 생활합니다. 이 사람들의 대부분은 오랫동안 이곳에 있었습니다. 그 중 많은 사람들이 전쟁 전에 이곳에 있었습니다. 이 사람들은 일하러 이곳에 왔습니다. 그 사람들은 여기에 문제가 없습니다. 그들은 전쟁이 없었기 때문에 여기에 있는 것이 아니기 때문에 그곳에서도 문제가 없습니다. 그러나 문제는 그들이 새 집이나 아파트를 살 돈이 없다는 것입니다. 그 때문에 많은 사람들이 돈이 없었습니다. 그래서 그들이 한국에 왔을 때 돈이 없었기 때문에 떠나야 했습니다. 그러다가 한국전쟁이 끝난 후 우리 민족 중 일부가 떠났습니다. 한국전쟁이 끝난 후 우리는 어떤 경우에는 그들을 위해 더 나은 집을 얻을 수 있는 상황이 있었습니다. 그 이후로 우리 집은 개조되었습니다. 우리 국민은 이제 부모와 함께 살 수 있습니다. 아내와 저는 두 자녀가 있습니다\n"
      ],
      "metadata": {
        "id": "J9tDgIeFnpr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "def chatbot_model():\n",
        "    # 모델과 토크나이저를 로드합니다.\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "    model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            # 사용자로부터 입력을 받습니다.\n",
        "            input_text = input(\"You: \")\n",
        "\n",
        "            # 입력을 토크나이저로 인코딩하고 텐서로 변환합니다.\n",
        "            inputs = tokenizer.encode(input_text, return_tensors='pt')\n",
        "\n",
        "            # 모델을 이용해 응답을 생성합니다.\n",
        "            outputs = model.generate(inputs, max_length=150, num_return_sequences=1, no_repeat_ngram_size=2, temperature=0.7)\n",
        "\n",
        "            # 생성된 응답을 디코딩합니다.\n",
        "            response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "            print(f\"Chatbot: {response}\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nChatbot session ended.\")\n",
        "        return\n",
        "\n",
        "# 챗봇 모델을 실행합니다.\n",
        "chatbot_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knOgM7tVoy39",
        "outputId": "450e6dbc-f8c5-45f5-f33b-545e3da0d7bb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: hi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chatbot: hi, who was born in the city of Kolkata, was a member of the Kargil movement. He was also a student of Srinagar University.\n",
            "\n",
            "\"I was in a state of shock when I heard about the incident. I was shocked to learn that the police had arrested a man for allegedly raping a girl in Karkali,\" he said. \"I had been in touch with the local police and they had informed me that they were investigating the case. The police have also informed us that a case has been registered against the accused. We are now in contact with them and will file a report soon.\"\n",
            " (With inputs from PTI)\n",
            "You: kkk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot: kkk3r3q3n3m3uNzYXNjYWY2N2MjMzNjc3M2YjNmYzM3YmM4Y3ZjZmZWJmNhNgYwYWRlYJlZGJhZJkZM5ZhYnMmFjkYTjbWUyYWNjBzZkM0MgM1MhMnFkNlMkU5MlNwMwNyMxN0N1NnY0Y1YTY1ZzQwZTkLm\n",
            "\n",
            "Chatbot session ended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPT-2 모델은 사전 훈련 시에 사용된 데이터에 따라 성능이 크게 좌우됩니다. GPT-2는 기본적으로 영어 텍스트를 기반으로 훈련되었으며, 한국어에 대한 이해는 상대적으로 제한적입니다. 따라서 한국어에 대한 질문에 대한 답변은 영어에 비해 정확도가 낮을 수 있습니다.\n",
        "\n",
        "다만, 한국어에 특화된 사전 훈련 모델을 사용하면 한국어 처리 성능을 크게 향상시킬 수 있습니다. 예를 들어, OpenAI에서 제공하는 GPT-2의 한국어 버전이나, SKT에서 개발한 KoGPT2 등이 있습니다. 이런 모델들은 한국어 텍스트에 대해 더욱 높은 이해력과 성능을 보일 것입니다.\n",
        "\n",
        "물론, 이러한 모델도 완벽하게 모든 한국어 질문에 답변할 수 있는 것은 아닙니다. 언어 모델의 한계와 각 모델의 특성, 그리고 훈련 데이터의 특성 등을 이해하는 것이 중요합니다."
      ],
      "metadata": {
        "id": "zMFgFmWEq75t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "!pip install transformers\n",
        "\n",
        "\n",
        "이 명령어를 실행하면 transformers 라이브러리와 이 라이브러리가 의존하는 다른 라이브러리들이 설치됩니다. 이렇게 하면 GPT3LMHeadModel과 같은 클래스를 포함하는 transformers 라이브러리의 모든 기능을 사용할 수 있습니다.\n",
        "\n",
        "단, GPT-3를 사용하려면 OpenAI의 API 키가 필요하고, 이를 위해서는 OpenAI에 가입하고 API 키를 발급받아야 합니다. API 키는 요청에 대한 인증을 제공하며, 요청량에 대한 제한과 요금이 부과될 수 있습니다.\n",
        "\n",
        "또한, GPT-3 모델은 매우 크기 때문에, 충분한 계산 자원(CPU, GPU, 메모리 등)을 가진 머신에서 사용하는 것이 좋습니다.\n"
      ],
      "metadata": {
        "id": "i7BZoEKlrZ79"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Colab에서는 무한 루프를 중지하기 위해 웹 인터페이스의 '정지' 버튼을 클릭하거나 메뉴에서 '런타임 > 실행 중단'을 선택해야 합니다. 키보드의 Ctrl+C는 Google Colab의 웹 환경에서 파이썬 코드 실행을 중지하는 데에 직접적으로 작동하지 않습니다.\n",
        "\n",
        "이는 Google Colab이 웹 브라우저에서 실행되는 클라우드 기반의 환경이기 때문입니다. 일반적인 로컬 터미널 환경에서는 키보드 인터럽트(Ctrl+C)가 프로세스에 신호를 보내 실행을 중단하도록 하지만, Google Colab은 웹 브라우저에서 실행되므로 이러한 신호를 직접적으로 전달받지 못합니다.\n",
        "\n",
        "따라서 Google Colab에서는 웹 인터페이스에서 제공하는 '정지' 버튼을 이용해 무한루프를 중지하거나, 코드에 타임아웃을 설정하는 등의 방법을 사용해야 합니다."
      ],
      "metadata": {
        "id": "Si36ze56rsU-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "idJaBNaGr2sV"
      }
    }
  ]
}